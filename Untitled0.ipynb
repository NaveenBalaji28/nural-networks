{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0bKesvcqmQie",
        "outputId": "2b4afb2e-836b-4d0c-a2da-2f85afd0a524"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "columns: ['time', 'feature1', 'feature2', 'feature3', 'target']\n",
            "X_train.shape, y_train.shape: (776, 24, 3) (776,)\n",
            "X_test.shape, y_test.shape: (200, 24, 3) (200,)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m3\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m17,408\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">17,408</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,521\u001b[0m (76.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,521</span> (76.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,521\u001b[0m (76.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,521</span> (76.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "22/22 - 3s - 140ms/step - loss: 0.8859 - mae: 0.7576 - val_loss: 0.7331 - val_mae: 0.7139\n",
            "Epoch 2/30\n",
            "22/22 - 0s - 15ms/step - loss: 0.3741 - mae: 0.4915 - val_loss: 0.2473 - val_mae: 0.4130\n",
            "Epoch 3/30\n",
            "22/22 - 0s - 16ms/step - loss: 0.2518 - mae: 0.4045 - val_loss: 0.1827 - val_mae: 0.3611\n",
            "Epoch 4/30\n",
            "22/22 - 0s - 15ms/step - loss: 0.2040 - mae: 0.3614 - val_loss: 0.1395 - val_mae: 0.3077\n",
            "Epoch 5/30\n",
            "22/22 - 0s - 16ms/step - loss: 0.1741 - mae: 0.3308 - val_loss: 0.1150 - val_mae: 0.2874\n",
            "Epoch 6/30\n",
            "22/22 - 0s - 15ms/step - loss: 0.1826 - mae: 0.3417 - val_loss: 0.1647 - val_mae: 0.3176\n",
            "Epoch 7/30\n",
            "22/22 - 0s - 15ms/step - loss: 0.1224 - mae: 0.2817 - val_loss: 0.0933 - val_mae: 0.2538\n",
            "Epoch 8/30\n",
            "22/22 - 0s - 15ms/step - loss: 0.1333 - mae: 0.2908 - val_loss: 0.0845 - val_mae: 0.2364\n",
            "Epoch 9/30\n",
            "22/22 - 0s - 15ms/step - loss: 0.1270 - mae: 0.2825 - val_loss: 0.0767 - val_mae: 0.2269\n",
            "Epoch 10/30\n",
            "22/22 - 0s - 15ms/step - loss: 0.1274 - mae: 0.2808 - val_loss: 0.0654 - val_mae: 0.2080\n",
            "Epoch 11/30\n",
            "22/22 - 0s - 17ms/step - loss: 0.1104 - mae: 0.2640 - val_loss: 0.0619 - val_mae: 0.1992\n",
            "Epoch 12/30\n",
            "22/22 - 0s - 15ms/step - loss: 0.1142 - mae: 0.2653 - val_loss: 0.0597 - val_mae: 0.1965\n",
            "Epoch 13/30\n",
            "22/22 - 0s - 19ms/step - loss: 0.0978 - mae: 0.2506 - val_loss: 0.0627 - val_mae: 0.2031\n",
            "Epoch 14/30\n",
            "22/22 - 1s - 24ms/step - loss: 0.0977 - mae: 0.2466 - val_loss: 0.0545 - val_mae: 0.1834\n",
            "Epoch 15/30\n",
            "22/22 - 1s - 24ms/step - loss: 0.1011 - mae: 0.2459 - val_loss: 0.0632 - val_mae: 0.2054\n",
            "Epoch 16/30\n",
            "22/22 - 1s - 30ms/step - loss: 0.1090 - mae: 0.2616 - val_loss: 0.0565 - val_mae: 0.1849\n",
            "Epoch 17/30\n",
            "22/22 - 1s - 24ms/step - loss: 0.1229 - mae: 0.2727 - val_loss: 0.1004 - val_mae: 0.2607\n",
            "Epoch 18/30\n",
            "22/22 - 0s - 20ms/step - loss: 0.1083 - mae: 0.2598 - val_loss: 0.0569 - val_mae: 0.1895\n",
            "Epoch 19/30\n",
            "22/22 - 0s - 15ms/step - loss: 0.1056 - mae: 0.2550 - val_loss: 0.0870 - val_mae: 0.2442\n",
            "Epoch 20/30\n",
            "22/22 - 0s - 15ms/step - loss: 0.1002 - mae: 0.2511 - val_loss: 0.0536 - val_mae: 0.1842\n",
            "Epoch 21/30\n",
            "22/22 - 0s - 16ms/step - loss: 0.0949 - mae: 0.2464 - val_loss: 0.0552 - val_mae: 0.1886\n",
            "Epoch 22/30\n",
            "22/22 - 0s - 15ms/step - loss: 0.0935 - mae: 0.2421 - val_loss: 0.0511 - val_mae: 0.1714\n",
            "Epoch 23/30\n",
            "22/22 - 1s - 29ms/step - loss: 0.0923 - mae: 0.2379 - val_loss: 0.0557 - val_mae: 0.1898\n",
            "Epoch 24/30\n",
            "22/22 - 0s - 14ms/step - loss: 0.0907 - mae: 0.2367 - val_loss: 0.0558 - val_mae: 0.1886\n",
            "Epoch 25/30\n",
            "22/22 - 0s - 15ms/step - loss: 0.0880 - mae: 0.2351 - val_loss: 0.0551 - val_mae: 0.1868\n",
            "Epoch 26/30\n",
            "22/22 - 0s - 16ms/step - loss: 0.0918 - mae: 0.2349 - val_loss: 0.0577 - val_mae: 0.1949\n",
            "Epoch 27/30\n",
            "22/22 - 0s - 15ms/step - loss: 0.0935 - mae: 0.2450 - val_loss: 0.0542 - val_mae: 0.1859\n",
            "Epoch 28/30\n",
            "22/22 - 0s - 16ms/step - loss: 0.0881 - mae: 0.2343 - val_loss: 0.0633 - val_mae: 0.2068\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Deterministic test RMSE: 1.4715, MAE: 1.2081\n",
            "MC Dropout mean RMSE: 1.4756, MAE: 1.2060\n",
            "Saved probabilistic forecasts to: /mnt/data/predictions_with_intervals.csv\n",
            "Empirical coverage: 80% interval -> 0.660, 95% interval -> 0.820\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# -------------------- settings --------------------\n",
        "DATA_PATH = \"/content/time_series_dataset.csv\"   # <-- (provided uploaded file)\n",
        "OUT_PATH = \"/mnt/data/predictions_with_intervals.csv\"\n",
        "LOOKBACK = 24            # number of past timesteps used to predict next\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 30\n",
        "MC_SAMPLES = 200         # number of stochastic forward passes for MC Dropout\n",
        "TEST_SPLIT = 0.2\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "np.random.seed(RANDOM_SEED)\n",
        "tf.random.set_seed(RANDOM_SEED)\n",
        "random.seed(RANDOM_SEED)\n",
        "\n",
        "# -------------------- load data --------------------\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "# expect columns: time, feature1, feature2, feature3, target\n",
        "print(\"columns:\", df.columns.tolist())\n",
        "features = df.drop(columns=[\"time\", \"target\"], errors=\"ignore\").columns.tolist()\n",
        "target_col = \"target\"\n",
        "\n",
        "# -------------------- create sequences --------------------\n",
        "def create_sequences(data_df, feature_cols, target_col, lookback):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data_df) - lookback):\n",
        "        X.append(data_df[feature_cols].iloc[i:i+lookback].values)\n",
        "        y.append(data_df[target_col].iloc[i+lookback])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# train/test split by time (no shuffle)\n",
        "n_total = len(df)\n",
        "n_test = int(n_total * TEST_SPLIT)\n",
        "n_train = n_total - n_test\n",
        "train_df = df.iloc[:n_train].reset_index(drop=True)\n",
        "test_df = df.iloc[n_train - LOOKBACK:].reset_index(drop=True)  # include lookback overlap to build first test seq\n",
        "\n",
        "# scale features and target separately\n",
        "feat_scaler = StandardScaler()\n",
        "tgt_scaler = StandardScaler()\n",
        "\n",
        "feat_scaler.fit(train_df[features])\n",
        "tgt_scaler.fit(train_df[[target_col]])\n",
        "\n",
        "train_df_scaled = train_df.copy()\n",
        "train_df_scaled[features] = feat_scaler.transform(train_df[features])\n",
        "train_df_scaled[target_col] = tgt_scaler.transform(train_df[[target_col]])\n",
        "\n",
        "test_df_scaled = test_df.copy()\n",
        "test_df_scaled[features] = feat_scaler.transform(test_df[features])\n",
        "test_df_scaled[target_col] = tgt_scaler.transform(test_df[[target_col]])\n",
        "\n",
        "X_train, y_train = create_sequences(train_df_scaled, features, target_col, LOOKBACK)\n",
        "X_test, y_test = create_sequences(test_df_scaled, features, target_col, LOOKBACK)\n",
        "print(\"X_train.shape, y_train.shape:\", X_train.shape, y_train.shape)\n",
        "print(\"X_test.shape, y_test.shape:\", X_test.shape, y_test.shape)\n",
        "\n",
        "# -------------------- model with dropout for MC sampling --------------------\n",
        "def build_mc_lstm(input_shape, dropout_rate=0.2, lstm_units=64):\n",
        "    \"\"\"\n",
        "    Simple LSTM model with dropout layers. We will use Monte-Carlo dropout\n",
        "    by calling model(x, training=True) at prediction time to keep dropout active.\n",
        "    \"\"\"\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = layers.LSTM(lstm_units, return_sequences=False)(inputs)\n",
        "    x = layers.Dropout(dropout_rate)(x)\n",
        "    x = layers.Dense(32, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(dropout_rate)(x)\n",
        "    outputs = layers.Dense(1)(x)  # regression output\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
        "                  loss=\"mse\",\n",
        "                  metrics=[\"mae\"])\n",
        "    return model\n",
        "\n",
        "input_shape = X_train.shape[1:]  # (timesteps, features)\n",
        "model = build_mc_lstm(input_shape, dropout_rate=0.2, lstm_units=64)\n",
        "model.summary()\n",
        "\n",
        "# -------------------- training --------------------\n",
        "es = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=6, restore_best_weights=True)\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_split=0.1,\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    callbacks=[es],\n",
        "    verbose=2,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# -------------------- deterministic baseline prediction (for comparison) --------------------\n",
        "y_pred_det = model.predict(X_test, batch_size=BATCH_SIZE).squeeze()\n",
        "# inverse scale\n",
        "y_pred_det_inv = tgt_scaler.inverse_transform(y_pred_det.reshape(-1,1)).ravel()\n",
        "y_test_inv = tgt_scaler.inverse_transform(y_test.reshape(-1,1)).ravel()\n",
        "\n",
        "rmse_det = np.sqrt(mean_squared_error(y_test_inv, y_pred_det_inv))\n",
        "mae_det = mean_absolute_error(y_test_inv, y_pred_det_inv)\n",
        "print(f\"Deterministic test RMSE: {rmse_det:.4f}, MAE: {mae_det:.4f}\")\n",
        "\n",
        "# -------------------- Monte Carlo Dropout predictions --------------------\n",
        "# We'll run many forward passes with dropout active to obtain predictive distribution.\n",
        "mc_preds = np.zeros((MC_SAMPLES, X_test.shape[0]))\n",
        "\n",
        "for i in range(MC_SAMPLES):\n",
        "    # call model with training=True to enable dropout at inference (stochastic forward pass)\n",
        "    preds = model(X_test, training=True).numpy().squeeze()\n",
        "    mc_preds[i] = preds\n",
        "\n",
        "# Convert back to original scale\n",
        "mc_preds_inv = tgt_scaler.inverse_transform(mc_preds.T).T  # shape: (MC_SAMPLES, n_test)\n",
        "\n",
        "# Compute statistics\n",
        "mean_pred = np.mean(mc_preds_inv, axis=0)\n",
        "p2_5 = np.percentile(mc_preds_inv, 2.5, axis=0)\n",
        "p10 = np.percentile(mc_preds_inv, 10, axis=0)\n",
        "p90 = np.percentile(mc_preds_inv, 90, axis=0)\n",
        "p97_5 = np.percentile(mc_preds_inv, 97.5, axis=0)\n",
        "\n",
        "# Evaluate mean prediction\n",
        "rmse_mc = np.sqrt(mean_squared_error(y_test_inv, mean_pred))\n",
        "mae_mc = mean_absolute_error(y_test_inv, mean_pred)\n",
        "print(f\"MC Dropout mean RMSE: {rmse_mc:.4f}, MAE: {mae_mc:.4f}\")\n",
        "\n",
        "# -------------------- prepare output dataframe --------------------\n",
        "# Align test times: the test_df started at index (n_train - LOOKBACK), and we created len(X_test) sequences\n",
        "# We'll take time index from test_df corresponding to prediction times\n",
        "prediction_times = test_df[\"time\"].iloc[LOOKBACK:].reset_index(drop=True)\n",
        "\n",
        "out_df = pd.DataFrame({\n",
        "    \"time\": prediction_times,\n",
        "    \"y_true\": y_test_inv,\n",
        "    \"pred_mean\": mean_pred,\n",
        "    \"pred_p2_5\": p2_5,\n",
        "    \"pred_p10\": p10,\n",
        "    \"pred_p90\": p90,\n",
        "    \"pred_p97_5\": p97_5\n",
        "})\n",
        "\n",
        "# Add additional columns if desired: width of intervals\n",
        "out_df[\"interval_80_width\"] = out_df[\"pred_p90\"] - out_df[\"pred_p10\"]\n",
        "out_df[\"interval_95_width\"] = out_df[\"pred_p97_5\"] - out_df[\"pred_p2_5\"]\n",
        "\n",
        "# Create the output directory if it doesn't exist\n",
        "os.makedirs(os.path.dirname(OUT_PATH), exist_ok=True)\n",
        "out_df.to_csv(OUT_PATH, index=False)\n",
        "print(\"Saved probabilistic forecasts to:\", OUT_PATH)\n",
        "\n",
        "# -------------------- quick checks --------------------\n",
        "# Coverage check: fraction of true values within intervals\n",
        "coverage_80 = np.mean((out_df[\"y_true\"] >= out_df[\"pred_p10\"]) & (out_df[\"y_true\"] <= out_df[\"pred_p90\"]))\n",
        "coverage_95 = np.mean((out_df[\"y_true\"] >= out_df[\"pred_p2_5\"]) & (out_df[\"y_true\"] <= out_df[\"pred_p97_5\"]))\n",
        "print(f\"Empirical coverage: 80% interval -> {coverage_80:.3f}, 95% interval -> {coverage_95:.3f}\")\n",
        "\n",
        "# -------------------- done --------------------\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Try to import keras-tuner (different package names)\n",
        "try:\n",
        "    import keras_tuner as kt\n",
        "except Exception:\n",
        "    try:\n",
        "        # Ensure keras-tuner is installed. If not, install it.\n",
        "        %pip install keras-tuner --quiet\n",
        "        import keras_tuner as kt  # alias\n",
        "    except Exception:\n",
        "        raise ImportError(\"Please install keras-tuner (pip install keras-tuner) before running this script.\")\n",
        "\n",
        "# -------------------- Settings --------------------\n",
        "DATA_PATH = \"/content/time_series_dataset.csv\"  # uploaded dataset path (use as URL in other tools)\n",
        "OUT_DIR = \"/mnt/data\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "tf.random.set_seed(RANDOM_SEED)\n",
        "random.seed(RANDOM_SEED)\n",
        "\n",
        "MAX_TRIALS = 25        # tuner trials (reduce/increase depending on compute)\n",
        "EXECUTION_PER_TRIAL = 1\n",
        "EPOCHS = 40\n",
        "BATCH_SIZE = 32\n",
        "TEST_SPLIT = 0.2\n",
        "\n",
        "# -------------------- Utility functions --------------------\n",
        "def rmse(y_true, y_pred):\n",
        "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "\n",
        "def create_sequences(df, feature_cols, target_col, lookback):\n",
        "    X, y = [], []\n",
        "    for i in range(len(df) - lookback):\n",
        "        X.append(df[feature_cols].iloc[i:i+lookback].values)\n",
        "        y.append(df[target_col].iloc[i+lookback])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "def save_report(text):\n",
        "    with open(os.path.join(OUT_DIR, \"report.txt\"), \"a\", encoding=\"utf-8\") as f:\n",
        "        f.write(text + \"\\n\")\n",
        "\n",
        "# -------------------- Load and document dataset --------------------\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "start_time = datetime.utcnow().isoformat()\n",
        "report_header = f\"Attention-LSTM Pipeline Report\\nStarted: {start_time} UTC\\nData source (local path): {DATA_PATH}\\n\\n\"\n",
        "open(os.path.join(OUT_DIR, \"report.txt\"), \"w\").write(report_header)\n",
        "\n",
        "print(\"Dataset columns:\", df.columns.tolist())\n",
        "save_report(\"Dataset columns: \" + \", \".join(df.columns.tolist()))\n",
        "save_report(f\"Dataset shape: {df.shape}\")\n",
        "save_report(\"First 5 rows:\\n\" + df.head().to_string())\n",
        "\n",
        "# Expect columns: time, feature1, feature2, feature3, target (robust to extra columns)\n",
        "if \"time\" not in df.columns:\n",
        "    df.insert(0, \"time\", np.arange(len(df)))\n",
        "\n",
        "# -------------------- Dataset characteristics --------------------\n",
        "# Quick stats\n",
        "desc = df.describe().to_string()\n",
        "save_report(\"\\nDataset descriptive statistics:\\n\" + desc)\n",
        "\n",
        "# -------------------- Prepare train/test split (time-based) --------------------\n",
        "feature_cols = [c for c in df.columns if c not in (\"time\", \"target\")]\n",
        "target_col = \"target\"\n",
        "\n",
        "n_total = len(df)\n",
        "n_test = int(n_total * TEST_SPLIT)\n",
        "n_train = n_total - n_test\n",
        "train_df = df.iloc[:n_train].reset_index(drop=True)\n",
        "test_df = df.iloc[n_train - 100:].reset_index(drop=True)  # keep lookback overlap margin; tuner will choose lookback\n",
        "\n",
        "save_report(f\"\\nTrain rows: {len(train_df)}, Test rows (with overlap): {len(test_df)}\")\n",
        "\n",
        "# -------------------- Scaling --------------------\n",
        "feat_scaler = StandardScaler().fit(train_df[feature_cols])\n",
        "tgt_scaler = StandardScaler().fit(train_df[[target_col]])\n",
        "\n",
        "train_scaled = train_df.copy()\n",
        "train_scaled[feature_cols] = feat_scaler.transform(train_df[feature_cols])\n",
        "train_scaled[target_col] = tgt_scaler.transform(train_df[[target_col]])\n",
        "\n",
        "test_scaled = test_df.copy()\n",
        "test_scaled[feature_cols] = feat_scaler.transform(test_df[feature_cols])\n",
        "test_scaled[target_col] = tgt_scaler.transform(test_df[[target_col]])\n",
        "\n",
        "# -------------------- Model builders --------------------\n",
        "def build_attention_lstm_model(hp, input_shape):\n",
        "    \"\"\"\n",
        "    Build Attention-LSTM model for Keras-Tuner.\n",
        "    Architecture:\n",
        "      - LSTM (return_sequences=True)\n",
        "      - (Optional) a second LSTM (return_sequences=True) - controlled by hp\n",
        "      - MultiHeadAttention applied where query=value=LSTM outputs\n",
        "      - GlobalAveragePooling or flatten -> Dense -> output\n",
        "    We also create a model wrapper that exposes the attention layer object for later inspection.\n",
        "    \"\"\"\n",
        "    inputs = keras.Input(shape=input_shape, name=\"inputs\")\n",
        "    x = inputs\n",
        "\n",
        "    lstm_units = hp.Int(\"lstm_units\", min_value=16, max_value=128, step=16, default=64)\n",
        "    return_seq = True\n",
        "    x = layers.LSTM(lstm_units, return_sequences=return_seq, name=\"lstm_1\")(x)\n",
        "    if hp.Boolean(\"use_second_lstm\", default=False):\n",
        "        lstm_units2 = hp.Int(\"lstm_units_2\", 8, 128, step=8, default=32)\n",
        "        x = layers.LSTM(lstm_units2, return_sequences=True, name=\"lstm_2\")(x)\n",
        "\n",
        "    dropout_rate = hp.Float(\"dropout\", 0.0, 0.5, step=0.1, default=0.2)\n",
        "    x = layers.Dropout(dropout_rate, name=\"dropout\")(x)\n",
        "\n",
        "    # Attention params\n",
        "    att_heads = hp.Int(\"att_heads\", 1, 8, step=1, default=2)\n",
        "    att_key_dim = hp.Int(\"att_key_dim\", 8, 64, step=8, default=16)\n",
        "\n",
        "    # MultiHeadAttention: query=key=value = x (self-attention on sequence)\n",
        "    # We'll set return_attention_scores=True during a separate call to obtain att scores.\n",
        "    mha = layers.MultiHeadAttention(num_heads=att_heads, key_dim=att_key_dim, name=\"mha\")\n",
        "    att_out = mha(query=x, value=x, key=x)  # shape: (batch, timesteps, key_dim * num_heads)\n",
        "    # Optionally add residual connection and normalization\n",
        "    x = layers.Add(name=\"res_add\")([x, att_out])\n",
        "    x = layers.LayerNormalization(name=\"att_layernorm\")(x)\n",
        "\n",
        "    # Pool across time (or use attention pooling)\n",
        "    pooling = hp.Choice(\"pooling\", [\"avg\", \"flatten\", \"last\"], default=\"avg\")\n",
        "    if pooling == \"avg\":\n",
        "        x = layers.GlobalAveragePooling1D(name=\"gap\")(x)\n",
        "    elif pooling == \"last\":\n",
        "        x = layers.Lambda(lambda z: z[:, -1, :], name=\"last_timestep\")(x)\n",
        "    else:\n",
        "        x = layers.Flatten(name=\"flatten\")(x)\n",
        "\n",
        "    dense_units = hp.Int(\"dense_units\", 8, 128, step=8, default=32)\n",
        "    x = layers.Dense(dense_units, activation=\"relu\", name=\"dense\")(x)\n",
        "    x = layers.Dropout(dropout_rate)(x)\n",
        "    outputs = layers.Dense(1, name=\"output\")(x)\n",
        "\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"Attention_LSTM\")\n",
        "    lr = hp.Float(\"lr\", 1e-4, 1e-2, sampling=\"log\", default=1e-3)\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr), loss=\"mse\", metrics=[\"mae\"])\n",
        "    # attach the mha layer object for later use (non-serializable property, but we will rebuild when needed)\n",
        "    model.mha_layer = mha\n",
        "    return model\n",
        "\n",
        "def build_baseline_lstm(input_shape, lstm_units=64, dropout_rate=0.2, dense_units=32, lr=1e-3):\n",
        "    inputs = keras.Input(shape=input_shape, name=\"inputs\")\n",
        "    x = layers.LSTM(lstm_units, return_sequences=False, name=\"lstm_baseline\")(inputs)\n",
        "    x = layers.Dropout(dropout_rate)(x)\n",
        "    x = layers.Dense(dense_units, activation=\"relu\")(x)\n",
        "    outputs = layers.Dense(1)(x)\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"Baseline_LSTM\")\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr), loss=\"mse\", metrics=[\"mae\"])\n",
        "    return model\n",
        "\n",
        "# -------------------- Keras Tuner setup --------------------\n",
        "def tuner_search(train_scaled, feature_cols, target_col, max_trials=MAX_TRIALS):\n",
        "    # We'll allow tuner to choose LOOKBACK as well by passing lookback via hp in outer wrapper\n",
        "    def model_builder(hp):\n",
        "        # hp for lookback is outer; but Keras Tuner expects model input shape fixed - so we'll set lookback externally.\n",
        "        # To use tuner-chosen lookback, we create a closure value after tuner chooses a lookback via HyperParameters\n",
        "        lookback = hp.Int(\"lookback\", 12, 72, step=12, default=24)\n",
        "        # Build sequences using this lookback - but tuner cannot change training data shape between trials easily.\n",
        "        # To keep tuner compatible, we will implement a strategy: choose a lookback BEFORE tuner search by sampling a small set.\n",
        "        # However, simpler: run tuner for fixed lookback (selected below), then do a separate tuner run if you want different lookbacks.\n",
        "        raise RuntimeError(\"model_builder should not be called directly in this wrapper\")\n",
        "\n",
        "    # Simpler approach (robust): perform tuner search for a fixed lookback value chosen here.\n",
        "    # You can repeat tuner_search with different LOOKBACK values to scan that hyperparameter too.\n",
        "    LOOKBACK = 24  # default; you can change this to 12/24/36/48 before running tuner_search\n",
        "    # Prepare sequences once\n",
        "    X_train_full, y_train_full = create_sequences(train_scaled, feature_cols, target_col, LOOKBACK)\n",
        "    print(\"Tuner will search with LOOKBACK =\", LOOKBACK, \"X_train_full.shape=\", X_train_full.shape)\n",
        "\n",
        "    def kt_model_builder(hp):\n",
        "        return build_attention_lstm_model(hp, input_shape=X_train_full.shape[1:])\n",
        "\n",
        "    tuner = kt.RandomSearch(\n",
        "        kt_model_builder,\n",
        "        objective=kt.Objective(\"val_loss\", direction=\"min\"),\n",
        "        max_trials=max_trials,\n",
        "        executions_per_trial=EXECUTION_PER_TRIAL,\n",
        "        directory=os.path.join(OUT_DIR, \"kt_dir\"),\n",
        "        project_name=\"att_lstm_search\",\n",
        "        overwrite=True,\n",
        "        seed=RANDOM_SEED,\n",
        "    )\n",
        "\n",
        "    stop_early = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=6, restore_best_weights=True)\n",
        "    tuner.search(X_train_full, y_train_full, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=0.1, callbacks=[stop_early], verbose=2)\n",
        "    best_hp = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "    best_model = tuner.get_best_models(num_models=1)[0]\n",
        "    # Save best model (weights)\n",
        "    best_model.save(os.path.join(OUT_DIR, \"attention_lstm_best.h5\"))\n",
        "    return best_model, best_hp, LOOKBACK\n",
        "\n",
        "# -------------------- Run tuner (Attention-LSTM) --------------------\n",
        "save_report(\"\\n\\n=== Hyperparameter tuning for Attention-LSTM ===\")\n",
        "print(\"Starting hyperparameter search (this may take some time)...\")\n",
        "best_model, best_hp, chosen_lookback = tuner_search(train_scaled, feature_cols, target_col, max_trials=MAX_TRIALS)\n",
        "\n",
        "save_report(f\"Chosen LOOKBACK (used for tuner run): {chosen_lookback}\")\n",
        "save_report(\"Best hyperparameters found:\")\n",
        "for k in best_hp.values.keys():\n",
        "    save_report(f\"  {k}: {best_hp.get(k)}\")\n",
        "\n",
        "# -------------------- Prepare final train/test sequences using chosen_lookback --------------------\n",
        "LOOKBACK = chosen_lookback\n",
        "# Recreate train/test splits that align with lookback\n",
        "train_df_final = df.iloc[:n_train].reset_index(drop=True)\n",
        "test_df_final = df.iloc[n_train - LOOKBACK:].reset_index(drop=True)\n",
        "\n",
        "train_scaled_final = train_df_final.copy()\n",
        "train_scaled_final[feature_cols] = feat_scaler.transform(train_df_final[feature_cols])\n",
        "train_scaled_final[target_col] = tgt_scaler.transform(train_df_final[[target_col]])\n",
        "\n",
        "test_scaled_final = test_df_final.copy()\n",
        "test_scaled_final[feature_cols] = feat_scaler.transform(test_df_final[feature_cols])\n",
        "test_scaled_final[target_col] = tgt_scaler.transform(test_df_final[[target_col]])\n",
        "\n",
        "X_train, y_train = create_sequences(train_scaled_final, feature_cols, target_col, LOOKBACK)\n",
        "X_test, y_test = create_sequences(test_scaled_final, feature_cols, target_col, LOOKBACK)\n",
        "\n",
        "print(\"Final shapes -> X_train:\", X_train.shape, \"X_test:\", X_test.shape)\n",
        "\n",
        "# -------------------- Rebuild best Attention-LSTM architecture with best_hp and re-train on full train set --------------------\n",
        "def build_model_from_hp(hp, input_shape):\n",
        "    # Reuse builder but return compiled model\n",
        "    model = build_attention_lstm_model(hp, input_shape)\n",
        "    return model\n",
        "\n",
        "att_model = build_model_from_hp(best_hp, input_shape=X_train.shape[1:])\n",
        "# print model summary\n",
        "att_model.summary()\n",
        "\n",
        "callbacks = [keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=6, restore_best_weights=True)]\n",
        "history_att = att_model.fit(X_train, y_train, validation_split=0.1, epochs=EPOCHS, batch_size=BATCH_SIZE, callbacks=callbacks, verbose=2)\n",
        "\n",
        "# Save model\n",
        "att_model.save(os.path.join(OUT_DIR, \"attention_lstm_trained.h5\"))\n",
        "\n",
        "# -------------------- Baseline LSTM training --------------------\n",
        "# We'll set baseline hyperparams similar to best_hp for fairness\n",
        "baseline_units = int(best_hp.get(\"lstm_units\") if \"lstm_units\" in best_hp.values else 64)\n",
        "baseline_dropout = float(best_hp.get(\"dropout\") if \"dropout\" in best_hp.values else 0.2)\n",
        "baseline_lr = float(best_hp.get(\"lr\") if \"lr\" in best_hp.values else 1e-3)\n",
        "baseline_model = build_baseline_lstm(input_shape=X_train.shape[1:], lstm_units=baseline_units, dropout_rate=baseline_dropout, dense_units=32, lr=baseline_lr)\n",
        "baseline_model.summary()\n",
        "history_base = baseline_model.fit(X_train, y_train, validation_split=0.1, epochs=EPOCHS, batch_size=BATCH_SIZE, callbacks=callbacks, verbose=2)\n",
        "baseline_model.save(os.path.join(OUT_DIR, \"baseline_lstm.h5\"))\n",
        "\n",
        "# -------------------- Predictions, inverse-scaling and evaluation --------------------\n",
        "y_pred_att = att_model.predict(X_test, batch_size=BATCH_SIZE).squeeze()\n",
        "y_pred_base = baseline_model.predict(X_test, batch_size=BATCH_SIZE).squeeze()\n",
        "\n",
        "# Inverse scale\n",
        "y_pred_att_inv = tgt_scaler.inverse_transform(y_pred_att.reshape(-1,1)).ravel()\n",
        "y_pred_base_inv = tgt_scaler.inverse_transform(y_pred_base.reshape(-1,1)).ravel()\n",
        "y_test_inv = tgt_scaler.inverse_transform(y_test.reshape(-1,1)).ravel()\n",
        "\n",
        "# Metrics\n",
        "metrics = {}\n",
        "metrics[\"attention_rmse\"] = rmse(y_test_inv, y_pred_att_inv)\n",
        "metrics[\"attention_mae\"] = mean_absolute_error(y_test_inv, y_pred_att_inv)\n",
        "metrics[\"attention_r2\"] = r2_score(y_test_inv, y_pred_att_inv)\n",
        "\n",
        "metrics[\"baseline_rmse\"] = rmse(y_test_inv, y_pred_base_inv)\n",
        "metrics[\"baseline_mae\"] = mean_absolute_error(y_test_inv, y_pred_base_inv)\n",
        "metrics[\"baseline_r2\"] = r2_score(y_test_inv, y_pred_base_inv)\n",
        "\n",
        "print(\"Evaluation metrics:\", metrics)\n",
        "# Save metrics to report and CSV\n",
        "save_report(\"\\n\\n=== Final Evaluation Metrics (on held-out test set) ===\")\n",
        "save_report(\"Metric,Attention-LSTM,Baseline-LSTM\")\n",
        "save_report(f\"RMSE,{metrics['attention_rmse']:.6f},{metrics['baseline_rmse']:.6f}\")\n",
        "save_report(f\"MAE,{metrics['attention_mae']:.6f},{metrics['baseline_mae']:.6f}\")\n",
        "save_report(f\"R2,{metrics['attention_r2']:.6f},{metrics['baseline_r2']:.6f}\")\n",
        "\n",
        "# Save predictions CSVs\n",
        "times = test_df_final[\"time\"].iloc[LOOKBACK:].reset_index(drop=True)\n",
        "out_att = pd.DataFrame({\n",
        "    \"time\": times,\n",
        "    \"y_true\": y_test_inv,\n",
        "    \"pred_attention\": y_pred_att_inv\n",
        "})\n",
        "out_base = pd.DataFrame({\n",
        "    \"time\": times,\n",
        "    \"y_true\": y_test_inv,\n",
        "    \"pred_baseline\": y_pred_base_inv\n",
        "})\n",
        "out_att.to_csv(os.path.join(OUT_DIR, \"predictions_attention.csv\"), index=False)\n",
        "out_base.to_csv(os.path.join(OUT_DIR, \"predictions_baseline.csv\"), index=False)\n",
        "save_report(f\"\\nSaved predictions_attention.csv and predictions_baseline.csv to {OUT_DIR}\")\n",
        "\n",
        "# -------------------- Visualize attention weights --------------------\n",
        "# To obtain attention scores from the MultiHeadAttention layer, we need to call it directly with return_attention_scores=True.\n",
        "# But our model's attention layer was created inside build_attention_lstm_model; we saved 'mha' object as model.mha_layer previously only for tuner model.\n",
        "# We built att_model via build_attention_lstm_model that created an mha layer with name \"mha\".\n",
        "# We'll create a small submodel that outputs the LSTM outputs before MHA and then call the MHA layer directly to get scores.\n",
        "layer_names = [layer.name for layer in att_model.layers]\n",
        "print(\"Model layers:\", layer_names)\n",
        "\n",
        "# Determine the sequence output layer based on hyperparameters\n",
        "if best_hp.get(\"use_second_lstm\"):\n",
        "    seq_layer = \"lstm_2\"\n",
        "else:\n",
        "    seq_layer = \"lstm_1\"\n",
        "\n",
        "# Create extractor model: inputs -> LSTM outputs (sequence)\n",
        "extractor = keras.Model(inputs=att_model.input, outputs=att_model.get_layer(seq_layer).output)\n",
        "\n",
        "# Find mha layer in model\n",
        "mha_layer = None\n",
        "for layer in att_model.layers:\n",
        "    if isinstance(layer, layers.MultiHeadAttention) or layer.name == \"mha\":\n",
        "        mha_layer = layer\n",
        "        break\n",
        "if mha_layer is None:\n",
        "    raise RuntimeError(\"MultiHeadAttention layer not found in trained model.\")\n",
        "\n",
        "# Choose a few test examples to visualize\n",
        "num_examples = min(6, X_test.shape[0])\n",
        "example_idx = list(range(num_examples))  # first few\n",
        "# extract sequences for examples\n",
        "X_examples = X_test[example_idx]\n",
        "\n",
        "# Compute sequence outputs then call mha with return_attention_scores=True\n",
        "seq_outputs = extractor.predict(X_examples, batch_size=BATCH_SIZE)  # shape (num_examples, lookback, units)\n",
        "# Call mha: query=seq_outputs, value=seq_outputs, key=seq_outputs, return_attention_scores=True\n",
        "# Note: calling a layer directly will create new variables in graph if shapes mismatch; use the layer's call method.\n",
        "att_output, att_scores = mha_layer(query=seq_outputs, value=seq_outputs, key=seq_outputs, return_attention_scores=True)\n",
        "# att_scores shape: (batch, num_heads, query_seq_len, key_seq_len)\n",
        "# We will average across heads for visualization\n",
        "att_scores_avg = np.mean(att_scores, axis=1)  # shape (batch, query_len, key_len)\n",
        "\n",
        "# Plot heatmaps\n",
        "sns.set()\n",
        "for i in range(num_examples):\n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "    sns.heatmap(att_scores_avg[i], xticklabels=np.arange(-LOOKBACK+1,1), yticklabels=np.arange(-LOOKBACK+1,1),\n",
        "                cmap=\"viridis\", ax=ax)\n",
        "    ax.set_title(f\"Attention weights (avg heads) example idx {i}\")\n",
        "    ax.set_xlabel(\"Key timestep (relative index)\")\n",
        "    ax.set_ylabel(\"Query timestep (relative index)\")\n",
        "    img_path = os.path.join(OUT_DIR, f\"att_heatmap_{i}.png\")\n",
        "    fig.savefig(img_path, bbox_inches=\"tight\")\n",
        "    plt.close(fig)\n",
        "    save_report(f\"Saved attention heatmap: {img_path}\")\n",
        "\n",
        "# -------------------- Analyze attention patterns (text) --------------------\n",
        "analysis_text = \"\\n\\n=== Attention analysis ===\\n\"\n",
        "analysis_text += f\"Displayed {num_examples} attention heatmaps (avg across {mha_layer.num_heads} heads).\\n\"\n",
        "analysis_text += \"Rows = query positions (timesteps where model attends from); Columns = key positions (historical timesteps model attends to).\\n\"\n",
        "analysis_text += \"Values are attention weights averaged across heads. Values close to 1 indicate high focus on that historical position for the given query.\\n\"\n",
        "analysis_text += \"Interpretation guidance:\\n\"\n",
        "analysis_text += \" - Diagonal dominance indicates the model mostly attends close-by timesteps.\\n\"\n",
        "analysis_text += \" - Off-diagonal peaks indicate the model references older timesteps (seasonality) or abrupt shifts.\\n\"\n",
        "analysis_text += \" - Compare heatmaps to dataset features/time ranges to see if attention aligns with seasonal lags or abrupt jump points.\\n\"\n",
        "save_report(analysis_text)\n",
        "\n",
        "# -------------------- Final outputs summary --------------------\n",
        "end_time = datetime.utcnow().isoformat()\n",
        "summary = f\"\\n\\nPipeline finished at {end_time} UTC.\\nOutputs saved to {OUT_DIR}:\\n - predictions_attention.csv\\n - predictions_baseline.csv\\n - attention_lstm_trained.h5\\n - baseline_lstm.h5\\n - att_heatmap_*.png\\n - report.txt\\n\"\n",
        "print(summary)\n",
        "save_report(summary)\n"
      ],
      "metadata": {
        "id": "KDv-Sz2Hmi-1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b90a2382-0f6e-4e0d-a2df-48003f4249c4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 25 Complete [00h 00m 09s]\n",
            "val_loss: 0.07886311411857605\n",
            "\n",
            "Best val_loss So Far: 0.049884259700775146\n",
            "Total elapsed time: 00h 04m 54s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 42 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final shapes -> X_train: (776, 24, 3) X_test: (200, 24, 3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"Attention_LSTM\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Attention_LSTM\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ inputs (\u001b[38;5;33mInputLayer\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m3\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m112\u001b[0m)   │     \u001b[38;5;34m51,968\u001b[0m │ inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m56\u001b[0m)    │     \u001b[38;5;34m37,856\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m56\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ mha                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m56\u001b[0m)    │     \u001b[38;5;34m58,168\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│                     │                   │            │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ res_add (\u001b[38;5;33mAdd\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m56\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│                     │                   │            │ mha[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ att_layernorm       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m56\u001b[0m)    │        \u001b[38;5;34m112\u001b[0m │ res_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ last_timestep       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ att_layernorm[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mLambda\u001b[0m)            │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)        │      \u001b[38;5;34m1,368\u001b[0m │ last_timestep[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ output (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m25\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ inputs (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">51,968</span> │ inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">37,856</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ mha                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">58,168</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│                     │                   │            │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ res_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│                     │                   │            │ mha[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ att_layernorm       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span> │ res_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ last_timestep       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ att_layernorm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,368</span> │ last_timestep[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m149,497\u001b[0m (583.97 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">149,497</span> (583.97 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m149,497\u001b[0m (583.97 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">149,497</span> (583.97 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "22/22 - 4s - 199ms/step - loss: 0.7870 - mae: 0.6660 - val_loss: 0.5623 - val_mae: 0.6348\n",
            "Epoch 2/40\n",
            "22/22 - 0s - 13ms/step - loss: 0.3479 - mae: 0.4644 - val_loss: 0.1698 - val_mae: 0.3575\n",
            "Epoch 3/40\n",
            "22/22 - 0s - 12ms/step - loss: 0.2349 - mae: 0.3840 - val_loss: 0.0854 - val_mae: 0.2424\n",
            "Epoch 4/40\n",
            "22/22 - 0s - 12ms/step - loss: 0.1953 - mae: 0.3507 - val_loss: 0.0955 - val_mae: 0.2316\n",
            "Epoch 5/40\n",
            "22/22 - 0s - 12ms/step - loss: 0.2010 - mae: 0.3482 - val_loss: 0.0662 - val_mae: 0.2001\n",
            "Epoch 6/40\n",
            "22/22 - 0s - 13ms/step - loss: 0.1744 - mae: 0.3268 - val_loss: 0.0950 - val_mae: 0.2517\n",
            "Epoch 7/40\n",
            "22/22 - 0s - 12ms/step - loss: 0.1676 - mae: 0.3203 - val_loss: 0.1223 - val_mae: 0.2835\n",
            "Epoch 8/40\n",
            "22/22 - 0s - 12ms/step - loss: 0.1513 - mae: 0.3062 - val_loss: 0.0785 - val_mae: 0.2281\n",
            "Epoch 9/40\n",
            "22/22 - 0s - 12ms/step - loss: 0.1480 - mae: 0.3038 - val_loss: 0.1067 - val_mae: 0.2677\n",
            "Epoch 10/40\n",
            "22/22 - 0s - 13ms/step - loss: 0.1361 - mae: 0.2936 - val_loss: 0.1913 - val_mae: 0.3583\n",
            "Epoch 11/40\n",
            "22/22 - 0s - 12ms/step - loss: 0.1279 - mae: 0.2852 - val_loss: 0.0740 - val_mae: 0.2185\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"Baseline_LSTM\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Baseline_LSTM\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ inputs (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m3\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_baseline (\u001b[38;5;33mLSTM\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m)            │        \u001b[38;5;34m51,968\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m3,616\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ inputs (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_baseline (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">51,968</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,616</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m55,617\u001b[0m (217.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">55,617</span> (217.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m55,617\u001b[0m (217.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">55,617</span> (217.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "22/22 - 2s - 74ms/step - loss: 0.3287 - mae: 0.4438 - val_loss: 0.1509 - val_mae: 0.3161\n",
            "Epoch 2/40\n",
            "22/22 - 0s - 9ms/step - loss: 0.1133 - mae: 0.2691 - val_loss: 0.0899 - val_mae: 0.2408\n",
            "Epoch 3/40\n",
            "22/22 - 0s - 13ms/step - loss: 0.0872 - mae: 0.2364 - val_loss: 0.0588 - val_mae: 0.1972\n",
            "Epoch 4/40\n",
            "22/22 - 0s - 9ms/step - loss: 0.0759 - mae: 0.2232 - val_loss: 0.0575 - val_mae: 0.1896\n",
            "Epoch 5/40\n",
            "22/22 - 0s - 9ms/step - loss: 0.0732 - mae: 0.2180 - val_loss: 0.0575 - val_mae: 0.1844\n",
            "Epoch 6/40\n",
            "22/22 - 0s - 13ms/step - loss: 0.0743 - mae: 0.2190 - val_loss: 0.0585 - val_mae: 0.1903\n",
            "Epoch 7/40\n",
            "22/22 - 0s - 9ms/step - loss: 0.0717 - mae: 0.2166 - val_loss: 0.0597 - val_mae: 0.1951\n",
            "Epoch 8/40\n",
            "22/22 - 0s - 9ms/step - loss: 0.0713 - mae: 0.2152 - val_loss: 0.0579 - val_mae: 0.1918\n",
            "Epoch 9/40\n",
            "22/22 - 0s - 8ms/step - loss: 0.0678 - mae: 0.2114 - val_loss: 0.0621 - val_mae: 0.2025\n",
            "Epoch 10/40\n",
            "22/22 - 0s - 9ms/step - loss: 0.0664 - mae: 0.2076 - val_loss: 0.0594 - val_mae: 0.1954\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Evaluation metrics: {'attention_rmse': np.float64(2.8022608678015724), 'attention_mae': 2.3888521617375584, 'attention_r2': 0.1399973478788371, 'baseline_rmse': np.float64(1.7144665868351214), 'baseline_mae': 1.42129190401299, 'baseline_r2': 0.678085367766507}\n",
            "Model layers: ['inputs', 'lstm_1', 'lstm_2', 'dropout', 'mha', 'res_add', 'att_layernorm', 'last_timestep', 'dense', 'dropout_3', 'output']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7aa9310f2840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step\n",
            "\n",
            "\n",
            "Pipeline finished at 2025-11-24T08:51:27.215089 UTC.\n",
            "Outputs saved to /mnt/data:\n",
            " - predictions_attention.csv\n",
            " - predictions_baseline.csv\n",
            " - attention_lstm_trained.h5\n",
            " - baseline_lstm.h5\n",
            " - att_heatmap_*.png\n",
            " - report.txt\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3034080371.py:373: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  end_time = datetime.utcnow().isoformat()\n"
          ]
        }
      ]
    }
  ]
}