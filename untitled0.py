# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RNEPAfPZ_YIcDOp8njOhDfb35L8AKpOi
"""

import os
import random
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

# -------------------- settings --------------------
DATA_PATH = "/content/time_series_dataset.csv"   # <-- (provided uploaded file)
OUT_PATH = "/mnt/data/predictions_with_intervals.csv"
LOOKBACK = 24            # number of past timesteps used to predict next
BATCH_SIZE = 32
EPOCHS = 30
MC_SAMPLES = 200         # number of stochastic forward passes for MC Dropout
TEST_SPLIT = 0.2
RANDOM_SEED = 42

np.random.seed(RANDOM_SEED)
tf.random.set_seed(RANDOM_SEED)
random.seed(RANDOM_SEED)

# -------------------- load data --------------------
df = pd.read_csv(DATA_PATH)
# expect columns: time, feature1, feature2, feature3, target
print("columns:", df.columns.tolist())
features = df.drop(columns=["time", "target"], errors="ignore").columns.tolist()
target_col = "target"

# -------------------- create sequences --------------------
def create_sequences(data_df, feature_cols, target_col, lookback):
    X, y = [], []
    for i in range(len(data_df) - lookback):
        X.append(data_df[feature_cols].iloc[i:i+lookback].values)
        y.append(data_df[target_col].iloc[i+lookback])
    return np.array(X), np.array(y)

# train/test split by time (no shuffle)
n_total = len(df)
n_test = int(n_total * TEST_SPLIT)
n_train = n_total - n_test
train_df = df.iloc[:n_train].reset_index(drop=True)
test_df = df.iloc[n_train - LOOKBACK:].reset_index(drop=True)  # include lookback overlap to build first test seq

# scale features and target separately
feat_scaler = StandardScaler()
tgt_scaler = StandardScaler()

feat_scaler.fit(train_df[features])
tgt_scaler.fit(train_df[[target_col]])

train_df_scaled = train_df.copy()
train_df_scaled[features] = feat_scaler.transform(train_df[features])
train_df_scaled[target_col] = tgt_scaler.transform(train_df[[target_col]])

test_df_scaled = test_df.copy()
test_df_scaled[features] = feat_scaler.transform(test_df[features])
test_df_scaled[target_col] = tgt_scaler.transform(test_df[[target_col]])

X_train, y_train = create_sequences(train_df_scaled, features, target_col, LOOKBACK)
X_test, y_test = create_sequences(test_df_scaled, features, target_col, LOOKBACK)
print("X_train.shape, y_train.shape:", X_train.shape, y_train.shape)
print("X_test.shape, y_test.shape:", X_test.shape, y_test.shape)

# -------------------- model with dropout for MC sampling --------------------
def build_mc_lstm(input_shape, dropout_rate=0.2, lstm_units=64):
    """
    Simple LSTM model with dropout layers. We will use Monte-Carlo dropout
    by calling model(x, training=True) at prediction time to keep dropout active.
    """
    inputs = keras.Input(shape=input_shape)
    x = layers.LSTM(lstm_units, return_sequences=False)(inputs)
    x = layers.Dropout(dropout_rate)(x)
    x = layers.Dense(32, activation="relu")(x)
    x = layers.Dropout(dropout_rate)(x)
    outputs = layers.Dense(1)(x)  # regression output
    model = keras.Model(inputs, outputs)
    model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3),
                  loss="mse",
                  metrics=["mae"])
    return model

input_shape = X_train.shape[1:]  # (timesteps, features)
model = build_mc_lstm(input_shape, dropout_rate=0.2, lstm_units=64)
model.summary()

# -------------------- training --------------------
es = keras.callbacks.EarlyStopping(monitor="val_loss", patience=6, restore_best_weights=True)
history = model.fit(
    X_train, y_train,
    validation_split=0.1,
    epochs=EPOCHS,
    batch_size=BATCH_SIZE,
    callbacks=[es],
    verbose=2,
    shuffle=False
)

# -------------------- deterministic baseline prediction (for comparison) --------------------
y_pred_det = model.predict(X_test, batch_size=BATCH_SIZE).squeeze()
# inverse scale
y_pred_det_inv = tgt_scaler.inverse_transform(y_pred_det.reshape(-1,1)).ravel()
y_test_inv = tgt_scaler.inverse_transform(y_test.reshape(-1,1)).ravel()

rmse_det = np.sqrt(mean_squared_error(y_test_inv, y_pred_det_inv))
mae_det = mean_absolute_error(y_test_inv, y_pred_det_inv)
print(f"Deterministic test RMSE: {rmse_det:.4f}, MAE: {mae_det:.4f}")

# -------------------- Monte Carlo Dropout predictions --------------------
# We'll run many forward passes with dropout active to obtain predictive distribution.
mc_preds = np.zeros((MC_SAMPLES, X_test.shape[0]))

for i in range(MC_SAMPLES):
    # call model with training=True to enable dropout at inference (stochastic forward pass)
    preds = model(X_test, training=True).numpy().squeeze()
    mc_preds[i] = preds

# Convert back to original scale
mc_preds_inv = tgt_scaler.inverse_transform(mc_preds.T).T  # shape: (MC_SAMPLES, n_test)

# Compute statistics
mean_pred = np.mean(mc_preds_inv, axis=0)
p2_5 = np.percentile(mc_preds_inv, 2.5, axis=0)
p10 = np.percentile(mc_preds_inv, 10, axis=0)
p90 = np.percentile(mc_preds_inv, 90, axis=0)
p97_5 = np.percentile(mc_preds_inv, 97.5, axis=0)

# Evaluate mean prediction
rmse_mc = np.sqrt(mean_squared_error(y_test_inv, mean_pred))
mae_mc = mean_absolute_error(y_test_inv, mean_pred)
print(f"MC Dropout mean RMSE: {rmse_mc:.4f}, MAE: {mae_mc:.4f}")

# -------------------- prepare output dataframe --------------------
# Align test times: the test_df started at index (n_train - LOOKBACK), and we created len(X_test) sequences
# We'll take time index from test_df corresponding to prediction times
prediction_times = test_df["time"].iloc[LOOKBACK:].reset_index(drop=True)

out_df = pd.DataFrame({
    "time": prediction_times,
    "y_true": y_test_inv,
    "pred_mean": mean_pred,
    "pred_p2_5": p2_5,
    "pred_p10": p10,
    "pred_p90": p90,
    "pred_p97_5": p97_5
})

# Add additional columns if desired: width of intervals
out_df["interval_80_width"] = out_df["pred_p90"] - out_df["pred_p10"]
out_df["interval_95_width"] = out_df["pred_p97_5"] - out_df["pred_p2_5"]

# Create the output directory if it doesn't exist
os.makedirs(os.path.dirname(OUT_PATH), exist_ok=True)
out_df.to_csv(OUT_PATH, index=False)
print("Saved probabilistic forecasts to:", OUT_PATH)

# -------------------- quick checks --------------------
# Coverage check: fraction of true values within intervals
coverage_80 = np.mean((out_df["y_true"] >= out_df["pred_p10"]) & (out_df["y_true"] <= out_df["pred_p90"]))
coverage_95 = np.mean((out_df["y_true"] >= out_df["pred_p2_5"]) & (out_df["y_true"] <= out_df["pred_p97_5"]))
print(f"Empirical coverage: 80% interval -> {coverage_80:.3f}, 95% interval -> {coverage_95:.3f}")

# -------------------- done --------------------

